{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c771a6f",
   "metadata": {},
   "source": [
    "En este notebook se aplicara la fase 2 del workflow jerarquico.\n",
    "Ya no clasificaremos la macro categoria [cs, math, physics, ...]\n",
    "Ahora nos centraremos en clasificar las probabilidades de las subcategorias...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06105fc9",
   "metadata": {},
   "source": [
    "En este caso, en la fase 2, no solo tendremos un modelo b (TENDREMOS UNO POR CADA MACRO CATEGORIA), ya que cuando se entrenan las subcategorias no son toda juntas en el mismo saco. \n",
    "las subcategorias de cs se entrenan entre ellas, no mas.\n",
    "las subcategorias de math se entrenan entre ellas, no mas.\n",
    "y asi para todas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839f2a15",
   "metadata": {},
   "source": [
    "Esta fase hara lo siguiente.\n",
    "Recorrer cada area de estudio (fisica, matematicas, ciencias computacionales, ...) por separado\n",
    "cada que llega a un area, discrimina lo demas.\n",
    "entrenara un mlp para distinguir subcategorias\n",
    "se guardara de nuevo un .pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54822dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#parametros\n",
    "TEST_SIZE = 0.2\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "#paths\n",
    "CLEANED = \"/Users/morenx/Downloads/mt/codigos/cleanedv3.csv\"\n",
    "EMBEDD = \"/Users/morenx/Downloads/mt/embeddingspecter.npy\" \n",
    "LABEL = \"/Users/morenx/Downloads/mt/labelspecter.csv\"\n",
    "#data \n",
    "\n",
    "cleaned = pd.read_csv(CLEANED)\n",
    "X = np.load(EMBEDD)\n",
    "df = pd.read_csv(LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb788e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se entrenarán nuestros modelos especialistas para: ['Computer Science' 'Economics & Finance' 'Electrical Engineering'\n",
      " 'Mathematics' 'Physics' 'Quantitative Biology' 'Statistics']\n",
      "\n",
      "procesando: COMPUTER SCIENCE\n",
      "   > Total Papers: 20000\n",
      "   > Subcategorías a aprender: 40\n",
      " guardado exitosamente: modelo_B_Computer_Science.pkl\n",
      "\n",
      "procesando: ECONOMICS & FINANCE\n",
      "   > Total Papers: 9504\n",
      "   > Subcategorías a aprender: 12\n",
      " guardado exitosamente: modelo_B_Economics_and_Finance.pkl\n",
      "\n",
      "procesando: ELECTRICAL ENGINEERING\n",
      "   > Total Papers: 14153\n",
      "   > Subcategorías a aprender: 4\n",
      " guardado exitosamente: modelo_B_Electrical_Engineering.pkl\n",
      "\n",
      "procesando: MATHEMATICS\n",
      "   > Total Papers: 20000\n",
      "   > Subcategorías a aprender: 35\n",
      " guardado exitosamente: modelo_B_Mathematics.pkl\n",
      "\n",
      "procesando: PHYSICS\n",
      "   > Total Papers: 20000\n",
      "   > Subcategorías a aprender: 53\n",
      " guardado exitosamente: modelo_B_Physics.pkl\n",
      "\n",
      "procesando: QUANTITATIVE BIOLOGY\n",
      "   > Total Papers: 19886\n",
      "   > Subcategorías a aprender: 10\n",
      " guardado exitosamente: modelo_B_Quantitative_Biology.pkl\n",
      "\n",
      "procesando: STATISTICS\n",
      "   > Total Papers: 20000\n",
      "   > Subcategorías a aprender: 5\n",
      " guardado exitosamente: modelo_B_Statistics.pkl\n",
      "\n",
      "TODOS LOS MODELOS ESTÁN LISTOS\n"
     ]
    }
   ],
   "source": [
    "macro_categorias = df['macro_cat'].unique()\n",
    "print(f\"Se entrenarán nuestros modelos especialistas para: {macro_categorias}\\n\")\n",
    "\n",
    "for macro in macro_categorias:\n",
    "    print(f\"procesando: {macro.upper()}\")\n",
    "    #filtramos el area\n",
    "    indices = df[df[\"macro_cat\"] == macro].index\n",
    "\n",
    "    #subconjunto \n",
    "    df_sub = df.loc[indices].copy()\n",
    "    X_sub = X[indices] # embeddings correspondientes del area\n",
    "\n",
    "    conteo = df_sub['primary_cat'].value_counts()\n",
    "    clases_validas = conteo[conteo >= 10].index\n",
    "\n",
    "    mask_validos = df_sub['primary_cat'].isin(clases_validas)\n",
    "    #nos saltamos una clase si es que tiene pocos papers\n",
    "    if len(df_sub) < 50:\n",
    "        print(f\"nos saltamos: {macro} tiene muy pocos datos ({len(df_sub)}) para entrenar.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"   > Total Papers: {len(df_sub)}\")\n",
    "    print(f\"   > Subcategorías a aprender: {len(clases_validas)}\")\n",
    "    \n",
    "    ### preparamos el entrenamiento\n",
    "    le_especialista = LabelEncoder()\n",
    "    y_encoded = le_especialista.fit_transform(df_sub['primary_cat'])\n",
    "\n",
    "    #data split local por clase\n",
    "    X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(\n",
    "            X_sub, y_encoded, \n",
    "            test_size=TEST_SIZE, \n",
    "            random_state=RANDOM_STATE, \n",
    "            stratify=y_encoded\n",
    "        )\n",
    "    # construccion del mlp\n",
    "    mlp_b = MLPClassifier(\n",
    "        hidden_layer_sizes=(256, 128),\n",
    "        activation='relu',\n",
    "        solver='adam',\n",
    "        max_iter=100,\n",
    "        early_stopping=True,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    mlp_b.fit(X_train_b, y_train_b)\n",
    "    \n",
    "    # guardamos cada modelo\n",
    "    NOMBRE = macro.replace(' ', '_').replace('&', 'and')\n",
    "    NOMBRE_ARCHIVO = f\"modelo_B_{NOMBRE}.pkl\"\n",
    "    \n",
    "    paquete = {\n",
    "        'modelo': mlp_b,\n",
    "        'encoder': le_especialista,\n",
    "        'macro_cat': macro,\n",
    "        'test_accuracy': mlp_b.score(X_test_b, y_test_b)\n",
    "    }\n",
    "    \n",
    "    joblib.dump(paquete, NOMBRE_ARCHIVO)\n",
    "    print(f\" guardado exitosamente: {NOMBRE_ARCHIVO}\\n\")\n",
    "\n",
    "print(\"TODOS LOS MODELOS ESTÁN LISTOS\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cadb7f7",
   "metadata": {},
   "source": [
    "YA OBTENIDOS TODOS LOS MODELOS, CREAREMOS NUESTRO SISTEMA FINAL..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd3bf43",
   "metadata": {},
   "source": [
    "HAREMOS LA PRIMERA PRUEBA DE NUESTRO CODIGO..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "464764d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class ArxivSystem:\n",
    "    def __init__(self, models_path=\"./\", umbral_cs=0.30):\n",
    "        self.path = models_path\n",
    "        self.umbral_cs = umbral_cs\n",
    "\n",
    "        # modelo A (fase 1)\n",
    "        try:\n",
    "            ruta_modelo_a = '/Users/morenx/Downloads/mt/codigos/model_a_specter.pkl' \n",
    "\n",
    "            if not os.path.exists(ruta_modelo_a):\n",
    "                 ruta_modelo_a = os.path.join(self.path, '/Users/morenx/Downloads/mt/codigos/model_a_specter.pkl')\n",
    "\n",
    "            sistema_a = joblib.load(ruta_modelo_a)\n",
    "            self.model_a = sistema_a['modelo']\n",
    "            self.encoder_a = sistema_a['encoder']\n",
    "            print(\"Fase 1 cargada en memoria.\")\n",
    "        except FileNotFoundError:\n",
    "            raise Exception(f\" No se cargó el modelo Fase 1.\")\n",
    "\n",
    "        #  modelos especialistas en cada area\n",
    "        self.specialists_cache = {} \n",
    "\n",
    "        # umbral de optimizacion de CS\n",
    "        self.idx_cs = self.encoder_a.transform(['Computer Science'])[0]\n",
    "\n",
    "    def get_specialist(self, macro_cat):\n",
    "        safe_name = macro_cat.replace(' ', '_').replace('&', 'and')\n",
    "        return f\"modelo_B_{safe_name}.pkl\"\n",
    "\n",
    "    def load_specialist(self, macro_cat):\n",
    "        \"\"\"\n",
    "        Carga un especialista solo si no está ya en memoria.\n",
    "        \"\"\"\n",
    "        if macro_cat in self.specialists_cache:\n",
    "            return self.specialists_cache[macro_cat]\n",
    "        \n",
    "        # Es nuevo, cargarlo del disco\n",
    "        filename = self.get_specialist(macro_cat)\n",
    "        filepath = os.path.join(self.path, filename)\n",
    "        \n",
    "        if not os.path.exists(filepath):\n",
    "            return None # No existe especialista para esta clase \n",
    "            \n",
    "        print(f\" cargando especialista: {macro_cat}...\")\n",
    "        try:\n",
    "            sistema_b = joblib.load(filepath)\n",
    "            # Guardamos cache\n",
    "            self.specialists_cache[macro_cat] = sistema_b\n",
    "            return sistema_b\n",
    "        except Exception as e:\n",
    "            print(f\"Error al leer {filename}: {e}\")\n",
    "            return None\n",
    "\n",
    "    def predict(self, vector_embedding, return_full_path=False):\n",
    "        \"\"\"\n",
    "        Inferencia jerárquica para nuestros embeddings\n",
    "        \"\"\"\n",
    "        #  forma (1, 768)\n",
    "        vector = vector_embedding.reshape(1, -1)\n",
    "        \n",
    "        # FASE 1_ MODELO A [MACRO CATEGORIAS]\n",
    "        probs = self.model_a.predict_proba(vector)[0]\n",
    "        \n",
    "        # Umbral para probabilidades\n",
    "        pred_idx = np.argmax(probs)\n",
    "        \n",
    "        # Prioridad CS\n",
    "        if probs[self.idx_cs] > self.umbral_cs:\n",
    "            pred_idx = self.idx_cs\n",
    "            \n",
    "        macro_cat = self.encoder_a.inverse_transform([pred_idx])[0]\n",
    "        \n",
    "        # FASE 2_ MODELO B [ESPECIALISTAS]\n",
    "        specialist = self.load_specialist(macro_cat)\n",
    "        \n",
    "        if specialist is None:\n",
    "            # PEOR ESCENARIO: El modelo A predijo algo para lo que no entrenamos sub-modelo\n",
    "            final_pred = f\"{macro_cat} (General)\"\n",
    "        else:\n",
    "            model_b = specialist['modelo']\n",
    "            encoder_b = specialist['encoder']\n",
    "            \n",
    "            pred_sub_idx = model_b.predict(vector)[0]\n",
    "            final_pred = encoder_b.inverse_transform([pred_sub_idx])[0]\n",
    "            \n",
    "        if return_full_path:\n",
    "            return {'macro': macro_cat, 'sub': final_pred}\n",
    "        \n",
    "        return final_pred\n",
    "\n",
    "    def batch_predict(self, X_matrix):\n",
    "        \"\"\"Opción para predecir muchos papers a la vez\"\"\"\n",
    "        return [self.predict(vec) for vec in X_matrix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fb67264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fase 1 cargada en memoria.\n",
      "Probando Inferencia \n",
      " cargando especialista: Computer Science...\n",
      "Realidad: cs.DM\n",
      "Predicción: {'macro': 'Computer Science', 'sub': 'cs.FL'}\n",
      "\n",
      "Prueba Rápida (10 papers) \n",
      " cargando especialista: Electrical Engineering...\n",
      " cargando especialista: Quantitative Biology...\n",
      " cargando especialista: Statistics...\n",
      " cargando especialista: Mathematics...\n",
      "acertado Real: eess.SY | Pred: eess.SY\n",
      "erroneo Real: eess.AS | Pred: cs.CL\n",
      "acertado Real: eess.AS | Pred: eess.AS\n",
      "acertado Real: q-bio.MN | Pred: q-bio.MN\n",
      "acertado Real: q-bio.NC | Pred: q-bio.NC\n",
      "acertado Real: stat.AP | Pred: stat.AP\n",
      "acertado Real: math.RT | Pred: math.RT\n",
      "acertado Real: cs.SI | Pred: cs.SI\n",
      "erroneo Real: stat.ML | Pred: cs.LG\n",
      "acertado Real: q-bio.NC | Pred: q-bio.NC\n"
     ]
    }
   ],
   "source": [
    "PATH_MODELOS = \"/Users/morenx/Downloads/mt/modelos\"\n",
    "arxiv_bot = ArxivSystem(models_path=PATH_MODELOS)\n",
    "\n",
    "print(\"Probando Inferencia \")\n",
    "#  paper de prueba aleatorio\n",
    "paper_test = X[500] \n",
    "\n",
    "# revisamos etiqueta real\n",
    "real_label = df.iloc[500]['primary_cat']\n",
    "\n",
    "# pred\n",
    "resultado = arxiv_bot.predict(paper_test, return_full_path=True)\n",
    "\n",
    "print(f\"Realidad: {real_label}\")\n",
    "print(f\"Predicción: {resultado}\")\n",
    "\n",
    "#  Validación 10 papers\n",
    "print(\"\\nPrueba Rápida (10 papers) \")\n",
    "indices_random = np.random.choice(len(X), 10)\n",
    "X_sample = X[indices_random]\n",
    "y_real_sample = df.iloc[indices_random]['primary_cat'].values\n",
    "\n",
    "y_preds = arxiv_bot.batch_predict(X_sample)\n",
    "\n",
    "for real, pred in zip(y_real_sample, y_preds):\n",
    "    acierto = \"acertado\" if real == pred else \"erroneo\"\n",
    "    print(f\"{acierto} Real: {real} | Pred: {pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0cdd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUACIÓN FINAL: TOP-3 ACCURACY \n",
      "Evaluando 1000 papers...\n",
      " cargando especialista: Physics...\n",
      " cargando especialista: Economics & Finance...\n",
      "EXACT MATCH (Top-1): 0.6330\n",
      "TOP-3 ACCURACY:    0.8100\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "print(\"EVALUACIÓN FINAL: TOP-3 ACCURACY \")\n",
    "\n",
    "#1k paper de prueba\n",
    "n_test = 1000\n",
    "indices_random = np.random.choice(len(X), n_test, replace=False)\n",
    "X_sample = X[indices_random]\n",
    "\n",
    "raw_labels = df.iloc[indices_random]['primary_cat'].values\n",
    "legacy_mapping = {\n",
    "    'alg-geom': 'math.AG', 'funct-an': 'math.FA', 'q-alg': 'math.QA', 'dg-ga': 'math.DG',\n",
    "    'geo-alg': 'math.AG', 'cmp-lg': 'cs.CL', 'adap-org': 'nlin.AO', 'comp-gas': 'nlin.CG',\n",
    "    'chao-dyn': 'nlin.CD', 'patt-sol': 'nlin.PS', 'solv-int': 'nlin.SI',\n",
    "    'supr-con': 'cond-mat.supr-con', 'acc-phys': 'physics.acc-ph', 'chem-ph': 'physics.chem-ph',\n",
    "    'mat-ph': 'math-ph'\n",
    "}\n",
    "y_real = pd.Series(raw_labels).replace(legacy_mapping).values\n",
    "\n",
    "#  inicializamos el sistema manual (para acceder a probabilidades) \n",
    "aciertos_top3 = 0\n",
    "aciertos_top1 = 0 \n",
    "\n",
    "print(f\"Evaluando {n_test} papers...\")\n",
    "\n",
    "for i, vector in enumerate(X_sample):\n",
    "    # fase 1\n",
    "    res_fase1 = arxiv_bot.predict(vector, return_full_path=True) \n",
    "    macro_cat = res_fase1['macro']\n",
    "    \n",
    "    # fase 2\n",
    "    specialist = arxiv_bot.load_specialist(macro_cat)\n",
    "    \n",
    "    if specialist is None:\n",
    "        continue # no hubo un modelo b especialista asignado (ojala no pase )\n",
    "        \n",
    "    model_b = specialist['modelo']\n",
    "    encoder_b = specialist['encoder']\n",
    "    \n",
    "    # Obtenemos probabilidades de todas las subcategorías\n",
    "    probs = model_b.predict_proba(vector.reshape(1, -1))[0]\n",
    "    \n",
    "    # Obtenemos los índices de las 3 más altas\n",
    "    top3_indices = np.argsort(probs)[-3:][::-1]\n",
    "    top3_classes = encoder_b.inverse_transform(top3_indices)\n",
    "    \n",
    "    # Verificamos\n",
    "    real_label = y_real[i]\n",
    "    \n",
    "    if real_label == top3_classes[0]: # Fue la #1\n",
    "        aciertos_top1 += 1\n",
    "        aciertos_top3 += 1\n",
    "    elif real_label in top3_classes: # Estaba en la #2 o #3\n",
    "        aciertos_top3 += 1\n",
    "\n",
    "print(f\"EXACT MATCH (Top-1): {aciertos_top1/n_test:.4f}\")\n",
    "print(f\"TOP-3 ACCURACY:    {aciertos_top3/n_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b13b519",
   "metadata": {},
   "source": [
    "Teniendo en cuenta que nuestros datos cuentan con mas de 150 clases (muchas de ellas superpuestas) es un resultado bastante decente, aunque con algo mas de tiempo, se podria mejorar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14fb3b7",
   "metadata": {},
   "source": [
    "INTERPETACION DE RESULTADOS...\n",
    "\n",
    "Considero que la razon por la cual el modelo no tiene una precision mas alta, no se debe a que el modelo no haya aprendido como se debe, el problema no es que el modelo no distinga un paper de fisica con uno de economia, el problema es que se debe de confundir (por ejemplo, cs.LG[machine learning] y cs.AI[artificial inteligence]).\n",
    "al darle 3 oportunidades, acerto casi el 80% de las veces. Con esto podria concluir que el modelo entiende semantica perfectamente, solo se confunde por los prefijos de arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e10604e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": "gray"
         },
         "name": "Azar (Random)",
         "type": "bar",
         "x": [
          "Sistema Jerárquico"
         ],
         "y": [
          0.007
         ]
        },
        {
         "marker": {
          "color": "indianred"
         },
         "name": "Exact Match (Top-1)",
         "text": [
          "63.3%"
         ],
         "textposition": "auto",
         "type": "bar",
         "x": [
          "Sistema Jerárquico"
         ],
         "y": [
          0.633
         ]
        },
        {
         "marker": {
          "color": "teal"
         },
         "name": "Top-3 Accuracy",
         "text": [
          "81.0%"
         ],
         "textposition": "auto",
         "type": "bar",
         "x": [
          "Sistema Jerárquico"
         ],
         "y": [
          0.81
         ]
        }
       ],
       "layout": {
        "barmode": "group",
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Top-1 vs Top-3"
        },
        "yaxis": {
         "title": {
          "text": "Accuracy"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "valores_top1 = [0.6330] # 63.3%\n",
    "valores_top3 = [0.8100] # Tu 81%\n",
    "azar = [0.007] \n",
    "\n",
    "categorias = ['Sistema Jerárquico']\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Barra del Azar (Referencia)\n",
    "fig.add_trace(go.Bar(\n",
    "    x=categorias, y=azar, name='Azar (Random)', marker_color='gray'\n",
    "))\n",
    "\n",
    "# Barra Top-1\n",
    "fig.add_trace(go.Bar(\n",
    "    x=categorias, y=valores_top1, name='Exact Match (Top-1)', marker_color='indianred',\n",
    "    text=[f\"{v*100:.1f}%\" for v in valores_top1], textposition='auto'\n",
    "))\n",
    "\n",
    "# Barra Top-3\n",
    "fig.add_trace(go.Bar(\n",
    "    x=categorias, y=valores_top3, name='Top-3 Accuracy', marker_color='teal',\n",
    "    text=[f\"{v*100:.1f}%\" for v in valores_top3], textposition='auto'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Top-1 vs Top-3',\n",
    "    yaxis_title='Accuracy',\n",
    "    barmode='group'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ec0c5a",
   "metadata": {},
   "source": [
    "Esta grafica sera la prueba de que mi proyecto fue un exito. \n",
    "\n",
    "La barra gris, aunque no se vea mucho, son los papers que no se supieron clasificar y se asignaron al azar\n",
    "\n",
    "La barra roja, ese 60.9% representa las veces que el modelo acerto a la primera con seguridad. \n",
    "(por ejemplo, el paper de prueba era cs.AI y el modelo dijo con seguridad que es cs.AI)\n",
    "este modelo sufrio bastante por la ambiguedad de arxiv, ya que si el modelo dijo que el paper era cs.LG (machine learning) y el paper era stat.ML (machine learning pero en estadisica) el fallo contara como un cero\n",
    "\n",
    "La barra verde, ese 78.2% es el caso en el que mejor le va al modelo. representa las veces que la respuesta correcta estaba entre las 3 opciones que el modelo considero mas probables, es prueba de que el sistema SI es inteligente.\n",
    "\n",
    "Esta diferencia entre barra roja y verde significa una cosa, no es que el modelo se equivoque profundamente (por ejemplo, diciendo que un paper es de finanzas cuando en realidad es de biologia), es por que duda de cosas muy parecidas, como ya se conto anteriormente.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
