{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "628447ba",
   "metadata": {},
   "source": [
    "Â¿QUE ES EL FEW SHOT LEARNING?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b791f390",
   "metadata": {},
   "source": [
    "concepto el cual busca clasificar usando clases con muy pocas muestras etiquetadas. Entonces, en vez de entrenar un modelo que busque directamente aprender de los datos, esta tecnica ayuda a que el modelo \"aprenda a aprender\". Es decir, tener una representacion que funcione con pocos datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c021bf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "429219cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cargando modelo...\n",
      "Features (X): (123543, 768)\n",
      "Etiquetas (y): (123543, 2)\n"
     ]
    }
   ],
   "source": [
    "TEST_SIZE = 0.2\n",
    "RANDOM_STATE = 42\n",
    "#loading data\n",
    "print(\"cargando modelo...\")\n",
    "EMBEDD = \"/Users/morenx/Downloads/mt/arxiv_embeddings_sampled.npy\"\n",
    "LABEL = \"/Users/morenx/Downloads/mt/arxiv_labels2.csv\"\n",
    "\n",
    "X = np.load(EMBEDD)\n",
    "df_label = pd.read_csv(LABEL)\n",
    "y_macro = df_label[\"macro_cat\"]\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y_macro)\n",
    "\n",
    "#data size\n",
    "print(f\"Features (X): {X.shape}\")\n",
    "print(f\"Etiquetas (y): {df_label.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba892d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#datasplit \n",
    "##data split\n",
    "X_train, X_test, y_train_encoded, y_test_encoded = train_test_split(\n",
    "    X, \n",
    "    y_encoded, \n",
    "    test_size=TEST_SIZE, \n",
    "    random_state=RANDOM_STATE, \n",
    "    stratify=y_encoded\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d84fe328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Fewshot (Nearest Centroid)\n",
      "\n",
      "Resultados:\n",
      "Accuracy Global: 0.7526\n",
      "\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "      Computer Science       0.68      0.57      0.62      4000\n",
      "             Economics       0.23      0.68      0.34       352\n",
      "Electrical Engineering       0.60      0.80      0.69      2831\n",
      "           Mathematics       0.83      0.81      0.82      4000\n",
      "               Physics       0.95      0.83      0.88      4000\n",
      "  Quantitative Biology       0.84      0.83      0.83      3977\n",
      "  Quantitative Finance       0.85      0.81      0.83      1549\n",
      "            Statistics       0.74      0.68      0.70      4000\n",
      "\n",
      "              accuracy                           0.75     24709\n",
      "             macro avg       0.71      0.75      0.71     24709\n",
      "          weighted avg       0.78      0.75      0.76     24709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\" Fewshot (Nearest Centroid)\")\n",
    "\n",
    "# model (usaremos distancias euclideanas para hacer las comparaciones de palabras en el espacio de los embeddings)\n",
    "clf_centroid = NearestCentroid(metric='euclidean')\n",
    "\n",
    "# train\n",
    "clf_centroid.fit(X_train, y_train_encoded)\n",
    "\n",
    "# pred\n",
    "y_pred_centroid = clf_centroid.predict(X_test)\n",
    "\n",
    "# metricas\n",
    "print(\"\\nResultados:\")\n",
    "print(f\"Accuracy Global: {accuracy_score(y_test_encoded, y_pred_centroid):.4f}\\n\")\n",
    "print(classification_report(y_test_encoded, y_pred_centroid, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b9475f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27f4497c",
   "metadata": {},
   "source": [
    "No me sirvio esta tecnica, pero si puedo inferir algo que nos hara redefinir nuestros datos.\n",
    "El problema no es la falta de datos en economics, el problema es la calidad del espacio, no se sabe distinguir un paper de economics con uno de quantitative finance.\n",
    "Volvere a "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
